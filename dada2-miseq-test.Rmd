---
title: 'Data analysis using DADA2 on 16S rRNA sequencing - Miseq run test'
author: "Mona Parizadeh"
date: "January 2018"
output:
word_document: default
classoption: 4apaper
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning=FALSE,
                      message=FALSE,
                      dev = 'pdf',
                      fig.path = "graphics/plot",
                      fig.align="center")
```


#### Package preparation ####
# Install dada2 and get ready
#source("https://bioconductor.org/biocLite.R")
#biocLite("dada2")
biocLite("devtools")
library("devtools")
devtools::install_github("benjjneb/dada2")
library(dada2)
packageVersion("dada2")

path <- "~/../../data/users/mona/joel-fastq-files/"
list.files(path)

#### Filter and trim ####
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)

# Examine quality profiles of forward and reverse reads
plotQualityProfile(fnFs[1:2]) # forward reads 1 and 2
plotQualityProfile(fnRs[1:2]) # reverse reads 1 and 2
# The reverse reads are of significantly worse quality, especially at the end, which is common in Illumina sequencing

# Perform filtering and trimming 
filt_path <- file.path(path, "filtered_noTrim") # Place filtered files in filtered/ subdirectory
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq.gz"))

# Filter the forward and reverse reads
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(260,240),
                     maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
                     compress=TRUE, verbose = TRUE, matchIDs = TRUE , multithread=TRUE) 

# matchIDs: match the paired reads by their Illumina ID
# On Windows set multithread=FALSE
# maxN = 0; After truncation (various at the end), sequences with more than maxN Ns will be discarded. Note that dada does not allow Ns.
# truncLen: Cut where the forward and reverse reads quality drop off, based on the plots (For paired-end reads consider the length of your amplicon when choosing  truncLen as your reads must overlap after truncation in order to merge them later).
head(out)

#### Calculate error rates ####
errF <- learnErrors(filtFs, multithread=TRUE) #1028345 
#Self-consistency loop terminated before convergence, even after 10 rounds.
errR <- learnErrors(filtRs, multithread=TRUE) #1028345 
#Self-consistency loop terminated before convergence, even after 10 rounds.
plotErrors(errF, nominalQ=TRUE)

#### Dereplicate the filtered fastq files ####
#Dereplication combines all identical sequencing reads into “unique sequences” with a corresponding “abundance”: the number of reads with that unique sequence, to reduce computation time by eliminating redundant comparisons
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names

#### Infer the sequence variants in each sample ####
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
dadaFs[[1]] #335 sequence variants were inferred from 10446 input unique sequences.
dadaRs[[1]] #259 sequence variants were inferred from 13146 input unique sequences.



#ddF <- dada(derepFs[1:40], err=NULL, selfConsist = TRUE, multithread = TRUE) #Convergence after  9  rounds.
#ddR <- dada(derepRs[1:40], err=NULL, selfConsist = TRUE, multithread = TRUE) #Convergence after  8  rounds.
#plotErrors(ddF)
#plotErrors(ddR)
#dadaFs <- dada(derepFs, err=ddF[[1]]$err_out, pool = TRUE)
#dadaRs <- dada(derepFs, err=ddR[[1]]$err_out, pool = TRUE)
#plotErrors(dadaFs, nominalQ = TRUE) + ggtitle("Forward")
#plotErrors(dadaRs, nominalQ = TRUE) + ggtitle("Reverse")

#### Merge the denoised forward and reverse reads ####
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE) # removes paired reads that did not exactly overlapped
# verbose = TRUE: to print a summary of the function results
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
# If the samples 0 paired-reads after merging, it means reads don't overlap. That is, the primers were separated by too much to meet in the middle.

#### Construct sequence table ####
seqtab <- makeSequenceTable(mergers) #The sequences being tabled vary in length.
dim(seqtab) #271 208551; seqtab is a matrix w/ rows corresponding to (and named by) the samples, and columns corresponding to (and named by) the sequence variants. 
# The lengths of the merged sequences should all fall within the expected range for this V4 amplicon.
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))

#### Remove chimeric sequences ####
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
#Identified 164928 bimeras out of 208551 input sequences.
dim(seqtab.nochim) #271 43623
sum(seqtab.nochim)/sum(seqtab) #0.7075365
#Most of your reads should remain after chimera removal (it is not uncommon for a majority of sequence variants to be removed though). If most of your reads were removed as chimeric, upstream processing may need to be revisited. In almost all cases this is caused by primer sequences with ambiguous nucleotides that were not removed prior to beginning the DADA2 pipeline.

#### Track reads through the pipeline ####
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(mergers, getN), rowSums(seqtab), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoised", "merged", "tabled", "nonchim")
rownames(track) <- sample.names
head(track)

#### Assign taxonomy ####
# Download RDP taxonomic training data formatted for DADA2 (rdp_train_set_16.fa.gz) from https://zenodo.org/record/801828#.Wi31VbQ-cWo
# Check for other datasets formatted for DADA2: https://benjjneb.github.io/dada2/training.html
taxa <- assignTaxonomy(seqtab.nochim, "~/../../data/users/mona/joel-fastq-files/rdp_train_set_16.fa.gz", multithread=TRUE)
unname(head(taxa))

#### Evaluating DADA2’s accuracy on the 17-1408 (for example) community ####
unqs.17.1408 <- seqtab.nochim["17-1408", ]
unqs.17.1408 <- sort(unqs.17.1408[unqs.17.1408>0], decreasing=TRUE)
cat("DADA2 inferred", length(unqs.17.1408), "sample sequences present in the 17-1408 community.\n")
#DADA2 inferred 322 sample sequences present in the 17-1408 community.

#### Phyloseq ####
biocLite('phyloseq')
library(phyloseq)
packageVersion("phyloseq") #‘1.20.0’

#install.packages("ggplot2")
library(ggplot2)
packageVersion("ggplot2") #‘2.2.1’

# Make a data.frame holding the sample data
samples.out <- rownames(seqtab.nochim)


